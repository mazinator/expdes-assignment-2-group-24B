{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286a034b-dc8b-4403-b0e0-3020bd193e99",
   "metadata": {},
   "source": [
    "# Reproduction of the paper's results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987bb533-d33f-4bc2-a3de-2b1e066f3751",
   "metadata": {},
   "source": [
    "## setup virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5fce48-ec5b-4e06-89c6-436ca8efcbc2",
   "metadata": {},
   "source": [
    "1. open new terminal and install python version manager:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90d06f24-837f-4ba8-aa1f-ecfa46e4d492",
   "metadata": {},
   "source": [
    "curl https://pyenv.run | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffb40fa-5f7e-4d55-8390-0235fec97699",
   "metadata": {},
   "source": [
    "2. download old python version from web: https://www.python.org/downloads/release/python-375rc1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f8b246-b643-4d01-b130-f6b93fe2ad08",
   "metadata": {},
   "source": [
    "3. also in Terminal, run these 4 commands to setup virtual environment:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ded75ca-f15f-4f36-98d5-e06f3a787739",
   "metadata": {},
   "source": [
    "python3.7 -m venv myenv-python37\n",
    "source myenv-python37/bin/activate (for Windows: myenv\\Scripts\\activate)\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --user --name=myenv-python37 --display-name=\"Python 3.7 (myenv-python37)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34c738a-5d4c-4eb4-baa6-1ba922a460d4",
   "metadata": {},
   "source": [
    "4. Afterwards, restart JupyterLab and select \"Python 3.7 (myenv-python37)\" as kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1124f1-d631-46e3-9d9e-1c8e251b4339",
   "metadata": {},
   "source": [
    "## Uninstall libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884ccb31-611e-49d3-8ebd-79e87e7ce02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 3.0.2\n",
      "Uninstalling transformers-3.0.2:\n",
      "  Successfully uninstalled transformers-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: torch 1.5.1\n",
      "Uninstalling torch-1.5.1:\n",
      "  Successfully uninstalled torch-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: pandas 1.0.5\n",
      "Uninstalling pandas-1.0.5:\n",
      "  Successfully uninstalled pandas-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: numpy 1.19.2\n",
      "Uninstalling numpy-1.19.2:\n",
      "  Successfully uninstalled numpy-1.19.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: scikit-learn 0.23.1\n",
      "Uninstalling scikit-learn-0.23.1:\n",
      "  Successfully uninstalled scikit-learn-0.23.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Skipping cython as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall --yes transformers\n",
    "%pip uninstall --yes torch\n",
    "%pip uninstall --yes pandas\n",
    "%pip uninstall --yes numpy\n",
    "%pip uninstall --yes scikit-learn\n",
    "%pip uninstall --yes cython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43cd38-6ab4-44bd-a815-9d5408c15923",
   "metadata": {},
   "source": [
    "## Install libraries with software versions stated in \"requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "236a7df5-3ab2-4048-a87b-440104685ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (23.3.2)\n",
      "Requirement already satisfied: setuptools in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (68.0.0)\n",
      "Requirement already satisfied: wheel in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (0.42.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting transformers==3.0.2\n",
      "  Using cached transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "Collecting numpy (from transformers==3.0.2)\n",
      "  Using cached numpy-1.21.6-cp37-cp37m-macosx_10_9_x86_64.whl (16.9 MB)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from transformers==3.0.2) (0.8.1rc1)\n",
      "Requirement already satisfied: packaging in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from transformers==3.0.2) (23.2)\n",
      "Requirement already satisfied: filelock in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from transformers==3.0.2) (3.12.2)\n",
      "Requirement already satisfied: requests in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from transformers==3.0.2) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from transformers==3.0.2) (4.66.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from transformers==3.0.2) (2023.12.25)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from transformers==3.0.2) (0.1.99)\n",
      "Requirement already satisfied: sacremoses in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from transformers==3.0.2) (0.0.53)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from requests->transformers==3.0.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from requests->transformers==3.0.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2023.11.17)\n",
      "Requirement already satisfied: six in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (1.3.2)\n",
      "Requirement already satisfied: importlib-metadata in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from click->sacremoses->transformers==3.0.2) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3.0.2) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3.0.2) (4.7.1)\n",
      "Installing collected packages: numpy, transformers\n",
      "Successfully installed numpy-1.21.6 transformers-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch==1.5.1\n",
      "  Using cached torch-1.5.1-cp37-none-macosx_10_9_x86_64.whl (80.5 MB)\n",
      "Requirement already satisfied: future in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from torch==1.5.1) (0.18.3)\n",
      "Requirement already satisfied: numpy in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from torch==1.5.1) (1.21.6)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas==1.0.5\n",
      "  Using cached pandas-1.0.5-cp37-cp37m-macosx_10_9_x86_64.whl (10.0 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from pandas==1.0.5) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from pandas==1.0.5) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from pandas==1.0.5) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas==1.0.5) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting numpy==1.19.2\n",
      "  Using cached numpy-1.19.2-cp37-cp37m-macosx_10_9_x86_64.whl (15.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "Successfully installed numpy-1.19.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn==0.23.1\n",
      "  Using cached scikit_learn-0.23.1-cp37-cp37m-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from scikit-learn==0.23.1) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from scikit-learn==0.23.1) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from scikit-learn==0.23.1) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from scikit-learn==0.23.1) (3.1.0)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-0.23.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: jupyter in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: ipywidgets in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (8.1.1)\n",
      "Requirement already satisfied: notebook in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jupyter) (6.5.6)\n",
      "Requirement already satisfied: qtconsole in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jupyter) (5.4.4)\n",
      "Requirement already satisfied: jupyter-console in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jupyter) (7.6.0)\n",
      "Requirement already satisfied: ipykernel in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jupyter) (6.16.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipywidgets) (7.34.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (68.0.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: decorator in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: backcall in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: appnope in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipykernel->jupyter) (1.7.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipykernel->jupyter) (7.4.9)\n",
      "Requirement already satisfied: nest-asyncio in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipykernel->jupyter) (1.5.8)\n",
      "Requirement already satisfied: packaging in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipykernel->jupyter) (23.2)\n",
      "Requirement already satisfied: psutil in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipykernel->jupyter) (5.9.7)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipykernel->jupyter) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from ipykernel->jupyter) (6.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jupyter-console->jupyter) (4.12.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (6.7.0)\n",
      "Requirement already satisfied: jinja2>=3.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (3.1.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (0.7.4)\n",
      "Requirement already satisfied: nbformat>=5.7 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (5.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbconvert->jupyter) (1.2.1)\n",
      "Requirement already satisfied: argon2-cffi in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from notebook->jupyter) (23.1.0)\n",
      "Requirement already satisfied: ipython-genutils in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from notebook->jupyter) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from notebook->jupyter) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from notebook->jupyter) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from notebook->jupyter) (0.17.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from notebook->jupyter) (1.0.0)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from importlib-metadata>=3.6->nbconvert->jupyter) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from importlib-metadata>=3.6->nbconvert->jupyter) (4.7.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbclassic>=0.4.7->notebook->jupyter) (1.24.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbclassic>=0.4.7->notebook->jupyter) (0.2.3)\n",
      "Requirement already satisfied: fastjsonschema in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.19.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from nbformat>=5.7->nbconvert->jupyter) (4.17.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.12)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.4.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter) (23.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter) (5.12.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter) (0.19.3)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (3.7.1)\n",
      "Requirement already satisfied: websocket-client in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.6.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.15.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.2.0)\n",
      "Requirement already satisfied: pycparser in /Users/danielmazanek/myenv-python37/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%jupyter` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip setuptools wheel\n",
    "%pip install transformers==3.0.2\n",
    "%pip install torch==1.5.1\n",
    "%pip install pandas==1.0.5\n",
    "%pip install numpy==1.19.2\n",
    "%pip install scikit-learn==0.23.1\n",
    "%pip install --upgrade jupyter ipywidgets\n",
    "%jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16539c7e-d3e8-4ea7-9ce4-50afb816812b",
   "metadata": {},
   "source": [
    "## Functions to be added by us before running author's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8688978f-4b0a-4faf-8956-96b6961f9a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is needed because the delimiter \",\" is also apparent in some queries\n",
    "def process_row(row):\n",
    "    if row['label'] not in ['m', 'n', 'f']:\n",
    "        row[\"query\"] = row[\"query\"] + row[\"label\"]\n",
    "        row[\"label\"] = row[\"other\"]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ebbc7-05b3-4269-929b-4343e8dde241",
   "metadata": {},
   "source": [
    "## Author's code for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad03c97-e94c-49e3-8d33-3b036bcd9adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dataset: (3707, 2) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def process_row(row):\n",
    "    if row['label'] not in ['m', 'n', 'f']:\n",
    "        row[\"query\"] = row[\"query\"] + row[\"label\"]\n",
    "        row[\"label\"] = row[\"other\"]\n",
    "    return row\n",
    "# importing libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "#Defining some key variables for preprocessing step\n",
    "class_names = ['Female', 'Male' , 'Neutral']\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
    "MAX_LEN = 33\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "VALID_BATCH_SIZE = 1\n",
    "EPOCHS = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "#Dataset\n",
    "class GenderBiasDataset(Dataset):\n",
    "\n",
    "    def __init__(self, queries, targets, tokenizer, max_len):\n",
    "        self.queries = queries\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        query_text = str(self.queries[index])\n",
    "        target = self.targets[index]\n",
    "         \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            query_text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        return {\n",
    "                'query': query_text,\n",
    "                'input_ids': torch.tensor(encoding['input_ids'], dtype=torch.long),\n",
    "                'attention_mask': torch.tensor(encoding['attention_mask'], dtype=torch.long),\n",
    "                'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "#Dataloader\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = GenderBiasDataset(\n",
    "        queries = df['query'].to_numpy(),\n",
    "        targets = df['label'].to_numpy(),\n",
    "        tokenizer  =tokenizer,\n",
    "        max_len = max_len\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = 1\n",
    "    )\n",
    "\n",
    "#Training function\n",
    "def train_epoch(model, data_loader, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels = targets\n",
    "        )\n",
    "        _, preds = torch.max(outputs[1], dim=1)  # the second return value is logits\n",
    "        loss = outputs[0] #the first return value is loss\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "#Evaluation function - used when adopting K-fold\n",
    "def eval_model(model, data_loader, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels = targets\n",
    "            )\n",
    "        _, preds = torch.max(outputs[1], dim=1)\n",
    "        loss = outputs[0]\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "#Prediction function - used to calculate the accuracy of the model when true labels are available\n",
    "def get_predictions(model, data_loader):\n",
    "    model = model.eval()\n",
    "    query_texts = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    real_values = []\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            texts = d[\"query\"]\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "            \tlabels = targets\n",
    "              )\n",
    "        _, preds = torch.max(outputs[1], dim=1)\n",
    "        query_texts.extend(texts)\n",
    "        predictions.extend(preds)\n",
    "        prediction_probs.extend(outputs[1])\n",
    "        real_values.extend(targets)\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "    real_values = torch.stack(real_values).cpu()\n",
    "    return query_texts, predictions, prediction_probs, real_values\n",
    "\n",
    "\n",
    "#Fine-Tuning the BERT on the Dataset\n",
    "result = open(\"BERT_Tuninig_results.txt\", \"w\")\n",
    "\n",
    "#=======NOTE: THE FOLLOWING SECTION HAS BEEN CHANGED===============\n",
    "df = pd.read_csv(\"./data/queries_gender_annotated.csv\", names = [\"index\", \"query\", \"label\", \"other\"])\n",
    "df['label'] = df['label'].astype(str)\n",
    "df = df.apply(process_row, axis=1)\n",
    "df.drop(columns=[\"index\", \"other\"], inplace=True)\n",
    "df = df[df['label'].isin(['m', 'n', 'f'])]\n",
    "labelEncoder = LabelEncoder()\n",
    "df['label'] = labelEncoder.fit_transform(df['label'])\n",
    "print(\"Shape of Dataset: {} \\n\".format(df.shape))\n",
    "wordlist = pd.read_csv(\"./data/wordlist_genderspecific.txt\", names = [\"query\", \"label\"])\n",
    "wordlist['label'] = labelEncoder.fit_transform(wordlist['label'])\n",
    "#df = pd.concat([df, wordlist], ignore_index = False)\n",
    "result.write(\"Shape of Dataset after concatination with wordlist: {} \\n\".format(df.shape))\n",
    "train_data_loader = create_data_loader(df, tokenizer, MAX_LEN, TRAIN_BATCH_SIZE)\n",
    "#df = df.head(40)\n",
    "#print(df.head(50))\n",
    "model = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels = 3) \n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(params =  model.parameters(), lr = LEARNING_RATE, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps = 0,\n",
    "            num_training_steps = total_steps\n",
    "        )\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    result.write(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    result.write(\"\\n\")\n",
    "    result.write('-' * 10)\n",
    "    result.write(\"\\n\")\n",
    "    train_acc, train_loss = train_epoch(\n",
    "                model,\n",
    "                train_data_loader,\n",
    "                optimizer,\n",
    "                device,\n",
    "                scheduler,\n",
    "                len(df)\n",
    "        )\n",
    "    result.write(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "    result.write(\"\\n\")\n",
    "\n",
    "torch.save(model.state_dict(), \"BERT_fine_tuned.bin\")\n",
    "result.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0901f5e-d3ac-4e11-864b-58b2bff4f7be",
   "metadata": {},
   "source": [
    "## Author's code for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8940cea-577c-4b8d-bf1e-cfcbe852af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# Constant variables \n",
    "class_names = ['Female', 'Male' , 'Neutral']\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "TEST_BATCH_SIZE = 16\n",
    "MAX_LEN = 55\n",
    "\n",
    "# Dataset\n",
    "class GenderBiasDataset(Dataset):\n",
    "\n",
    "    def __init__(self, queries, tokenizer, max_len):\n",
    "        self.queries = queries\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        query_text = str(self.queries[index])\n",
    "         \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            query_text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        return {\n",
    "                'query': query_text,\n",
    "                'input_ids': torch.tensor(encoding['input_ids'], dtype=torch.long),\n",
    "                'attention_mask': torch.tensor(encoding['attention_mask'], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Dataloader\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GenderBiasDataset(\n",
    "    queries = df['query'].to_numpy(),\n",
    "    tokenizer  =tokenizer,\n",
    "    max_len = max_len\n",
    "  )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size = batch_size,\n",
    "    num_workers = 5 \n",
    "  )\n",
    "\n",
    "#Prediction function\n",
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  query_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      texts = d[\"query\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs[0], dim=1)\n",
    "      query_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(outputs[0])\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  return query_texts, predictions, prediction_probs\n",
    "\n",
    "\n",
    "#Reading MSMarco dev set queries (these queires do not have label)\n",
    "df = pd.read_table(\"./data/msmacro.tsv\") # a dataframe containing the queries CHANGED LINE OF CODE\n",
    "test_data_loader = create_data_loader(df, tokenizer, MAX_LEN, TEST_BATCH_SIZE)\n",
    "\n",
    "#Loading the fine-tuned model - you can download the model from https://drive.google.com/file/d/1_YTRs4v5DVUGUffnRHS_3Yk4qteJKO6w/view?usp=sharing\n",
    "print(\"Loading the Model\")\n",
    "model = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels = 3)\n",
    "model.load_state_dict(torch.load(\"BERT_fine_tuned.bin\", map_location = device))\n",
    "print(\"Model Loaded Successfully\")\n",
    "\n",
    "print(\"Prediction started\")\n",
    "y_query_texts, y_pred, y_pred_probs = get_predictions(model, test_data_loader)\n",
    "prediction = pd.DataFrame(df.values.tolist(), columns = [\"qid\",\"query\"])\n",
    "prediction['female_probability'] = y_pred_probs[:, 0]\n",
    "prediction['male_probability'] = y_pred_probs[:, 1]\n",
    "prediction['neutral_probability'] = y_pred_probs[:, 2]\n",
    "prediction['prediction'] = y_pred\n",
    "prediction.to_csv(\"predictions.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244fbe3-138a-486d-a368-36cdc744d052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bf003-8f93-42cb-a1d2-14532baad711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e577c-af78-4b28-97ef-996017734832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63196552-255d-4f44-b29b-c3bd5556d6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6decea8e-03da-4420-9245-489d3964f9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cec2fd-9a10-4d67-b4e2-6a82c0e7a818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a0bd6-bade-4044-a874-1dbec50375b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063c8b2-cce9-4b70-9cac-7f508d05ec20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca1be5-8f0a-46bf-86ea-ec2dd8499108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8049a7e-ce42-460a-a984-6fafbf6c1b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3707, 2)\n",
      "(64, 2)\n",
      "(3771, 3)\n",
      "                                                query  label word\n",
      "0                   who was known as the heretic king      1  NaN\n",
      "1   who plays the main character in night at the m...      2  NaN\n",
      "2                                   what is surrogate      2  NaN\n",
      "3                       how popular is the name katie      0  NaN\n",
      "4          how much sleep in one day does a baby need      2  NaN\n",
      "5          what type of books does karen hesse write?      0  NaN\n",
      "6             can you drink coffee before a mammogram      2  NaN\n",
      "7                   what college did bill gates go to      1  NaN\n",
      "8       who was jacqueline kennedy's social secretary      0  NaN\n",
      "9                                    abbot definition      2  NaN\n",
      "10            concentra how old is a cat in one year.      2  NaN\n",
      "11                   when was stalins response speech      1  NaN\n",
      "12                             who is jennifer garner      0  NaN\n",
      "13              how many weeks can a puppy get spayed      2  NaN\n",
      "14                       who influenced pablo picasso      1  NaN\n",
      "15                 what year did james still graduate      1  NaN\n",
      "16                     actress who born at litrhuania      0  NaN\n",
      "17                                          what cow?      2  NaN\n",
      "18                            susan sarandon cup size      0  NaN\n",
      "19                              who is mark zuckerman      1  NaN\n",
      "20                               who played jake ryan      1  NaN\n",
      "21          who wrote song yesterday when i was young      2  NaN\n",
      "22                        when was actor karthik born      1  NaN\n",
      "23     which prep school did president kennedy attend      1  NaN\n",
      "24                 how much did freddie mercury weigh      1  NaN\n",
      "25                   when was mike tyson's last fight      1  NaN\n",
      "26              what instruments did john denver play      1  NaN\n",
      "27                              who is victoria lomba      0  NaN\n",
      "28  how old should your puppy be to get a rabies shot      2  NaN\n",
      "29                    what is produced during mitosis      2  NaN\n",
      "30                         why did van halen break up      1  NaN\n",
      "31                    who was richard the lionhearted      1  NaN\n",
      "32                        who is king philip of spain      1  NaN\n",
      "33         which microscope were cells first observed      2  NaN\n",
      "34                                  who was herodotus      1  NaN\n",
      "35            how many children does alicia keys have      0  NaN\n",
      "36                   what team did bill russell coach      1  NaN\n",
      "37             what has obama really done for america      1  NaN\n",
      "38                      where is alexander kentucky ?      1  NaN\n",
      "39                                      manual define      2  NaN\n",
      "40                       bruce willis die hard movies      1  NaN\n",
      "41                       who is steve brown comedian?      1  NaN\n",
      "42                                 where is kobenhavn      2  NaN\n",
      "43                did demi moore have plastic surgery      0  NaN\n",
      "44                     age of jennifer lopez pregnant      0  NaN\n",
      "45                              when did lou reed die      1  NaN\n",
      "46                     what happened in cabo shooting      2  NaN\n",
      "47                     distraction medical definition      2  NaN\n",
      "48                          who is richard henry less      1  NaN\n",
      "49           in what year is crepusculario published?      2  NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./data/queries_gender_annotated.csv\", names = [\"index\", \"query\", \"label\", \"other\"])\n",
    "df['label'] = df['label'].astype(str)\n",
    "df = df.apply(process_row, axis=1)\n",
    "df.drop(columns=[\"index\", \"other\"], inplace=True)\n",
    "df = df[df['label'].isin(['m', 'n', 'f'])]\n",
    "print(df.shape)\n",
    "labelEncoder = LabelEncoder()\n",
    "df['label'] = labelEncoder.fit_transform(df['label'])\n",
    "#result.write(\"Shape of Dataset: {} \\n\".format(df.shape))\n",
    "wordlist = pd.read_csv(\"./data/wordlist_genderspecific.txt\", names = [\"word\", \"label\"])\n",
    "wordlist['label'] = labelEncoder.fit_transform(wordlist['label'])\n",
    "print(wordlist.shape)\n",
    "df = pd.concat([df, wordlist], ignore_index = False)\n",
    "#result.write(\"Shape of Dataset after concatination with wordlist: {} \\n\".format(df.shape))\n",
    "print(df.shape)\n",
    "print(df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5638569c-e990-4e07-aadb-31aa47823814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index     30168\n",
      "query    328609\n",
      "label     30168\n",
      "word     122659\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d9aee-c99c-41bb-b265-77f181c1a3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3707, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def process_row(row):\n",
    "    if row['label'] not in ['m', 'n', 'f']:\n",
    "        row[\"query\"] = row[\"query\"] + row[\"label\"]\n",
    "        row[\"label\"] = row[\"other\"]\n",
    "    return row\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Minimal Dataset class\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        # Ensure labels are integers\n",
    "        item['labels'] = torch.tensor(int(self.labels[idx]))\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Load and preprocess a small part of the dataset\n",
    "df = pd.read_csv(\"./data/queries_gender_annotated.csv\", names = [\"index\", \"query\", \"label\", \"other\"])\n",
    "df['label'] = df['label'].astype(str)\n",
    "df = df.apply(process_row, axis=1)\n",
    "df.drop(columns=[\"index\", \"other\"], inplace=True)\n",
    "df = df[df['label'].isin(['m', 'n', 'f'])]\n",
    "print(df.shape)\n",
    "labelEncoder = LabelEncoder()\n",
    "df['label'] = labelEncoder.fit_transform(df['label'])\n",
    "\n",
    "# Encode the data\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encodings = tokenizer(df['query'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "# Ensure labels are integers\n",
    "labels = [int(label) for label in df['label'].tolist()]\n",
    "\n",
    "# Create a minimal dataset and dataloader\n",
    "dataset = SimpleDataset(encodings, labels)\n",
    "data_loader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "# Load model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Run a single batch through the model\n",
    "for batch in data_loader:\n",
    "    input_ids = batch['input_ids'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    attention_mask = batch['attention_mask'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    labels = batch['labels'].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "    print(outputs)\n",
    "    break  # Only test with the first batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (myenv-python37)",
   "language": "python",
   "name": "myenv-python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
